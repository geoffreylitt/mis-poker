---
layout: "../layouts/Layout.astro"
---

import UniformCardDemo from "../components/UniformCardDemo.jsx";
import FaceBiasedDemo from "../components/FaceBiasedDemo.jsx";
import WeightedAverageDemo from "../components/WeightedAverageDemo.jsx";
import WeightedConvergenceDemo from "../components/WeightedConvergenceDemo.jsx";
import MISComparisonDemo from "../components/MISComparisonDemo.jsx";
import MISConvergenceDemo from "../components/MISConvergenceDemo.jsx";
import PokerStraightDemo from "../components/PokerStraightDemo.jsx";

# Sampling interesting data with MIS

Imagine you're building a poker AI and need to answer this question: **"In heads-up Texas Hold'em, when both players have a straight, what's the probability that Player A wins?"**

If you try to estimate that by dealing random poker hands, you'll quickly discover a problem. You could deal thousands of hands and only see a small number of cases where both players have straights.

This is the core challenge: **how do you get enough data about rare events to make reliable estimates?**

## Introducing multiple importance sampling

The answer is a technique called **Multiple Importance Sampling**. The basic idea is simple:

> Sample more from "interesting" parts of the space, but track how much you're oversampling and correct for it later.

Think of it like political polling. Instead of calling random phone numbers, you might oversample from voter registration lists, political rally attendees, and social media groups. But then you must reweight each response based on how likely you were to reach that type of person. This gives you better estimates with fewer total calls.

Before we tackle poker hands, let's start with something much simpler. We'll draw cards from a standard deck and track the **average numeric rank** (we'll treat the face cards as A=1, J=11, Q=12, K=13) and **face card rate** (should be 3/13 ~= 23.1%). We can confirm these stats by drawing some cards:

<UniformCardDemo client:load />

This gives us our baseline. With uniform sampling, the average rank converges to 7.0 and face cards appear about 23.1% of the time. What we've just demonstrated is sampling from the **target distribution**—the distribution we actually care about. In this case, it's uniform over all 52 cards, so every card has probability 1/52.

## The problem with biased sampling

Now let's try something different. What if we oversample face cards—making Jacks, Queens, and Kings three times more likely to appear? This biased sampling represents a **proposal distribution**—an alternative way of generating samples that differs from our target. Face cards now have probability 3/52 each, while other cards still have probability 1/52.

<FaceBiasedDemo client:load />

Notice what happens:

- Average rank converges to about 8.58 instead of 7.0 (since face cards get 3× weight: $\frac{4 \times 55 + 4 \times 36 \times 3}{40 + 12 \times 3} = \frac{652}{76} = 8.58$)
- Face card rate jumps to about 46.2% instead of 23.1%

This demonstrates the fundamental problem with biased sampling: **you get biased estimates**.

## The Fix: Importance Weights

Here's the key insight: we can correct for the bias mathematically using **importance weights**.

For each sample, we compute:

$$\text{Weight} = \frac{P(\text{sample in target distribution})}{P(\text{sample in proposal distribution})}$$

In our example:

- **Face cards**: Weight = $\frac{1/52}{3/52} = \frac{1}{3}$
- **Regular cards**: Weight = $\frac{1/52}{1/52} = 1$

Then we compute a **weighted average**:

$$\text{Corrected Estimate} = \frac{\sum (\text{value} \times \text{weight})}{\sum \text{weight}}$$

Let's see this correction in action by stepping through some individual cards. Try clicking next until you find a face card—those cards are oversampled by 3×, so we downweight them by 1/3 to compensate.

<WeightedAverageDemo client:load />

For each card, we show:

- The card and its rank value
- Whether it came from biased sampling (face cards 3× more likely)
- The importance weight calculation: $\frac{P(\text{target})}{P(\text{proposal})}$
- How this weight affects the running weighted average

Watch how the weighted average converges toward 7.0 even though we're drawing from biased samples.

### Formal Definition: Importance Sampling

This technique is called **importance sampling**. We're sampling from a proposal distribution $q(x)$ but want to estimate expectations under the target distribution $p(x)$. The importance weight for sample $x$ is:

$$w(x) = \frac{p(x)}{q(x)}$$

And our estimator becomes:

$$E[f(X)] \approx \frac{1}{N} \sum_{i=1}^{N} f(x_i) \cdot w(x_i)$$

Let's see both approaches side by side to really drive home the difference.

<WeightedConvergenceDemo client:load />

- **Red line**: Naive average from biased samples (converges to wrong answer ~8.58)
- **Green line**: Weighted average using importance sampling (converges to correct answer ~7.0)

This demonstrates the power of importance sampling: we can use biased samples but still get unbiased estimates through proper reweighting.

## Multiple Proposals: The Next Challenge

So far we've used one biased proposal distribution. But what if we want to study multiple aspects simultaneously? For instance, what if we're interested in both face cards AND red cards?

We could run separate studies with different proposal distributions:

1. **Face card bias**: Jacks, Queens, Kings are 3× more likely
2. **Red card bias**: Hearts and Diamonds are 2× more likely

But it's more efficient to combine samples from both approaches. This leads us to **Multiple Importance Sampling**.

### To remember, or not?

The straightforward approach is to remember which proposal generated each sample, then apply the appropriate weight:

- Sample from face proposal → weight = $\frac{p(\text{card})}{p_{\text{face}}(\text{card})}$
- Sample from red proposal → weight = $\frac{p(\text{card})}{p_{\text{red}}(\text{card})}$

But there's a more sophisticated approach that doesn't require remembering the source. Instead of using the weight from the actual proposal, we can use a **combined weight** that considers all proposals:

$$\text{Weight} = \frac{p(\text{card})}{\alpha_1 \cdot p_{\text{face}}(\text{card}) + \alpha_2 \cdot p_{\text{red}}(\text{card})}$$

Where $\alpha_1$ and $\alpha_2$ are the mixing proportions (e.g., 50% from each proposal).

This might seem strange—why would this work when we're ignoring which proposal actually generated the sample?

The key insight is that **once we have a sample, it doesn't matter which proposal generated it**. A red Jack is a red Jack regardless of whether it came from the "face card bias" proposal or the "red card bias" proposal.

Think of it this way: instead of having separate proposals, imagine we have one meta-proposal that works like this:

1. First, randomly choose which proposal to use (e.g., 50% face bias, 50% red bias)
2. Then sample from that chosen proposal

From this perspective, the probability of getting any particular card is exactly the weighted mixture we use in the balance heuristic! The mathematical beauty is that this mixed probability automatically gives us the variance-minimizing weights.

When a sample could plausibly come from multiple proposals (like our red Jack), the balance heuristic naturally reduces its weight compared to the memory-based approach. This prevents any single "lucky" sample from having outsized influence on our estimate.

Let's see both approaches in action, step by step.

<MISComparisonDemo client:load />

For each card drawn, we show:

- Which proposal it actually came from (face biased or red biased)
- **Memory-based weight**: Using the actual source proposal
- **Memoryless weight**: Using the combined probability across all proposals
- How both contribute to running weighted averages

Notice that for some cards (like a red Jack), the weights differ significantly between approaches, but both averages should converge to the correct value of 7.0.

### Formal Definition: Balance Heuristic

The memoryless approach is called the **balance heuristic**. For a sample $x$, the weight is:

$$w(x) = \frac{p(x)}{\sum_j \frac{n_j}{N} \cdot q_j(x)}$$

Where:

- $p(x)$ is the target density
- $q_j(x)$ is the density under proposal $j$
- $\frac{n_j}{N}$ is the fraction of samples from proposal $j$

This weighting scheme is **provably optimal**—it minimizes the variance of the estimator among all possible ways of combining the proposals.

Let's see how both MIS approaches perform over time.

<MISConvergenceDemo client:load />

- **Orange line**: Memory-based MIS (tracks sample sources)
- **Cyan line**: Balance heuristic MIS (memoryless optimal weighting)

Both lines converge to the same value! We can see that the balance heuristic works, and simplifies our code.

## Future work / todos

We're not done yet.

To fully tackle the problem at the top of this essay, we'll need to move beyond drawing a single card. Dealing a specific kind of poker hand requires reasoning about _joint probabilities_ across multiple cards. So we'll need to consider questions like:

- how do we choose a good proposal distribution to increase the chance of satisfying a predicate like "both players have a straight"?
- how does the choice of proposal affect the results we end up with?
- can we construct a system that automatically chooses good proposals based on the user's desired predicate?

More on that soon!
